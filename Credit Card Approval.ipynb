{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BUSA3020 - Business Analytics - Assignment 1 {-}\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Assignment\n",
    "\n",
    "Credit score cards are used as a risk control method in the financial industry. Personal information submitted by credit card applicants are used to predict the probability of future defaults. The bank employs such data to decide whether to issue a credit card to the applicant or not.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| Income   | Annual income  |  |\n",
    "| Gender   | Applicant's Gender   | Male = 0, Female = 1  |\n",
    "| Car | Car Ownership | Yes = 1, No = 0 | \n",
    "| Children | Number of Children | |\n",
    "| Real Estate | Real Estate Ownership | Yes = 1, No = 0 \n",
    "| Days Since Birth | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| Days Employed | No. of Days | Count backwards from current day(0). If positive, it means the person is currently unemployed.\n",
    "| Payment Default | Whether a client has overdue credit card payments | Yes = 1, No = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Problem 1 - (50 points) {-}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** \n",
    "\n",
    "- Import the `assignment_data.xlsx` file from `data` folder into a pandas DataFrame named `df`; \n",
    "- Delete duplicate rows from `df` according to `ID`;\n",
    "- Delete the `ID` column.\n",
    "- How many rows are left in `df`?\n",
    "\n",
    "(10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"assignment_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows left in df: 5976\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows left in df: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "- Reset the index in `df` using an appropriate function from `pandas` so that the new index corresponds to the number of rows (make sure to delete the old index). \n",
    "- How many positive values of `Days Employed` are there?\n",
    "- Replace the positive values of `Days Employed` with 0 (zero) in `df`\n",
    "\n",
    "(10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_days_employed_count = (df['Days Employed'] > 0).sum()\n",
    "positive_days_employed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Days Employed'] > 0, 'Days Employed'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 3**\n",
    "\n",
    "Create two new variables in `df` named \n",
    "\n",
    "1. `Age`;\n",
    "2. `Years in Employment`,\n",
    "\n",
    "which measure age and employment length in **years** (decimal numbers) from `Days Since Birth` and `Days Employed` by applying approapriate transformations on these variables. \n",
    "\n",
    "Delete the original variables `Days Since Birth` and `Days Employed`.\n",
    "\n",
    "(5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']= abs(df['Days Since Birth']/365)\n",
    "df['Years in Employment']= abs(df['Days Employed']/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop('Days Since Birth',axis=1)\n",
    "df=df.drop('Days Employed', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 4**\n",
    "\n",
    "- Create a **one**-dimensional NumPy array named `y` by exporting the first 5,000 observations of `Payment_Default`. (Hint: see `ravel()` function)\n",
    "- Create a NumPy array named `X` by exporting the first 5,000 observations of the following columns `Gender`, `Car`, `Real Estate`, `Children`, `Income`, `Age`, `Years in Employment`.\n",
    " \n",
    "(10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Payment Default'].head(5000).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns=['Gender','Car','Real Estate','Children','Income','Age','Years in Employment']\n",
    "X=df[Columns].head(5000).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "**Question 5** \n",
    "\n",
    "- Use an appropriate `scikit-learn` library we learned in class to create the following NumPy arrays: `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 70% training and 30% test datasets. \n",
    "- Set `random_state` to 0 and stratify subsamples so that train and test datasets have roughly equal proportions of the target's class labels. \n",
    "\n",
    "(5 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (3500, 7)\n",
      "Shape of X_test: (1500, 7)\n",
      "Shape of y_train: (3500,)\n",
      "Shape of y_test: (1500,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 6**\n",
    "\n",
    "- Create new variables by using an appropriate `scikit-learn` library we learned in class to standardize the features from the training and test datasets to mean zero and variance one. Name the new variables by appending '_scaled' to the original variable names.\n",
    "\n",
    "\n",
    "(10 points)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_scaled_df: (3500, 7)\n",
      "Shape of X_test_scaled_df: (1500, 7)\n",
      "   Gender_scaled  Car_scaled  Real Estate_scaled  Children_scaled  \\\n",
      "0      -1.368782   -0.776250           -1.357651        -0.558100   \n",
      "1      -1.368782    1.288245            0.736566         0.681335   \n",
      "2      -1.368782    1.288245            0.736566        -0.558100   \n",
      "3       0.730577   -0.776250            0.736566         1.920770   \n",
      "4       0.730577   -0.776250           -1.357651        -0.558100   \n",
      "\n",
      "   Income_scaled  Age_scaled  Years in Employment_scaled  \n",
      "0       3.013142    0.971043                   -0.644484  \n",
      "1       0.284764   -0.747744                    0.015658  \n",
      "2      -0.494772    0.386946                   -0.677407  \n",
      "3      -0.884540   -0.757011                    0.176051  \n",
      "4      -0.105004   -0.597323                    0.690152  \n",
      "   Gender_scaled  Car_scaled  Real Estate_scaled  Children_scaled  \\\n",
      "0       0.730577    1.288245            0.736566        -0.558100   \n",
      "1      -1.368782    1.288245            0.736566         0.681335   \n",
      "2       0.730577   -0.776250           -1.357651        -0.558100   \n",
      "3      -1.368782    1.288245           -1.357651        -0.558100   \n",
      "4      -1.368782    1.288245            0.736566        -0.558100   \n",
      "\n",
      "   Income_scaled  Age_scaled  Years in Employment_scaled  \n",
      "0       2.233606   -1.368912                    0.238520  \n",
      "1      -0.105004    0.018617                   -0.094506  \n",
      "2      -0.494772    1.983115                   -0.936145  \n",
      "3      -0.105004   -0.303611                   -0.712018  \n",
      "4      -0.494772   -0.989415                   -0.766889  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=[col + '_scaled' for col in Columns])\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=[col + '_scaled' for col in Columns])\n",
    "\n",
    "print(f\"Shape of X_train_scaled_df: {X_train_scaled_df.shape}\")\n",
    "print(f\"Shape of X_test_scaled_df: {X_test_scaled_df.shape}\")\n",
    "\n",
    "print(X_train_scaled_df.head())\n",
    "print(X_test_scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 2 - (20 Points) {-}\n",
    "\n",
    "**Question 7**\n",
    "\n",
    "Fit the following two classifiers to the transformed training dataset using `scikit-learn` libraries.\n",
    "\n",
    "- Perceptron - name your instance `pc` set `random_state=1`\n",
    "- Logistic Regression - name your instance `lr` set `random_state=1`\n",
    "\n",
    "When initializing instances of the above classifiers only set the parameters referenced above and nothing else.\n",
    "\n",
    "(20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = Perceptron(random_state=1)\n",
    "pc.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr = LogisticRegression(random_state=1)\n",
    "lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3 - (30 points) {-}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**\n",
    "\n",
    "- Using a method built into each of the two classifiers compute their prediction accuracies on the training data;\n",
    "- Store the accuracy values into variables named according to the following pattern: `classifier_name_accuracy_train`, e.g. you should have `lr_accuracy_train`; \n",
    "- Print the two accuracy **variables** along with their brief descriptions.\n",
    "\n",
    "(10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron training accuracy: 0.496\n",
      "Logistic Regression training accuracy: 0.5577142857142857\n"
     ]
    }
   ],
   "source": [
    "pc_accuracy_train = pc.score(X_train_scaled, y_train)\n",
    "\n",
    "lr_accuracy_train = lr.score(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Perceptron training accuracy: {pc_accuracy_train}\")\n",
    "print(f\"Logistic Regression training accuracy: {lr_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 9** \n",
    "\n",
    "- Using a method built into each of the above classifiers compute their prediction accuracy for the test dataset\n",
    "- Store the accuracy values into variables named according to the following pattern: `classifier_name_accuracy_test`, e.g. you should have `lr_accuracy_test`. \n",
    "- Print the two accuracy **variables** along with brief descriptions.\n",
    "\n",
    "(10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron test accuracy: 0.49466666666666664\n",
      "Logistic Regression test accuracy: 0.5073333333333333\n"
     ]
    }
   ],
   "source": [
    "pc_accuracy_test = pc.score(X_test_scaled, y_test)\n",
    "lr_accuracy_test = lr.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Perceptron test accuracy: {pc_accuracy_test}\")\n",
    "print(f\"Logistic Regression test accuracy: {lr_accuracy_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 10** \n",
    "\n",
    "Using nicely formated text in Markdown comment on the accuracies computed in Questions 8 & 9 making sure you address:\n",
    "- training and test set datasets; \n",
    "- Perceptrion and Logistic Regression models. \n",
    "\n",
    "Are the results as expected, and why or why not? (Hint: You are not expected to comment on why a particular model is better.) \n",
    "\n",
    "(10 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Models            |  Training| Test |\n",
    "| :---------------- | :------: | ----: |\n",
    "| Perceptrion        |   0.496   | 0.558 |\n",
    "| Logistic Regression model |   0.494   | 0.507 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Output:\n",
    "The accuracies for the Perceptron and Logistic Regression Models on both the training and test datasets provides insights into the performance and generalisation capabilities of each model.\n",
    "\n",
    "#### Perceptron Model\n",
    "- **Training Accuracy: 49.6%** - indicates the Perceptron model is performing slightly better than random guessing (which would be 50%)\n",
    "- **Test Accuracy: 49.47%** - suggests that the model struggles to generalise to unseen data and might be underfitting, as its performance is almost equivalent to random guessing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Logistic Regression Model\n",
    "- **Training Accuracy: 55.77%** - indicates the Logistic Regression Model fits the training data better than the Perceptron model. \n",
    "- **Test Accuracy: 50.73%** - indicates a slight drop in performance when generalising to new data, but it still performs only marginally better than random guessing. \n",
    "\n",
    "\n",
    "#### Insights\n",
    "Both models show similar performance on the test data, which is close to 50%, indicating they struggle to make good predictions. \n",
    "\n",
    "The Logistic Regression model performs slightly better than the Perceptron on the training data, but neither model shows strong performance on the test data. This suggests that the data might not be well-suited to linear models, and we might need to use other models or features to improve predictions. \n",
    "\n",
    "In summary, the models are not performing well, especially on the new data. It indicates a need for further improvements in the modeling approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
